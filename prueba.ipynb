{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Tool from text processing  \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tool  \n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Regual expressions\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"OpenAi/amlo_clasify_chatpgt3.csv\")\n",
    "\n",
    "stop_words_es = stopwords.words('spanish')\n",
    "\n",
    "\n",
    "nlp = spacy.load('es_core_news_lg')\n",
    "\n",
    "\n",
    "def return_dataframe():\n",
    "\n",
    "    df['cla_num'] = df['Clasificacion'].apply(clasification_to_num)\n",
    "    df['Texto_limpio'] = df['Texto'].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# fn to clean text \n",
    "\n",
    "def clean_text(texto):\n",
    "  textofin = texto.lower()\n",
    "  textofin = re.sub(r'([^0-9A-Za-z-À-ÿ \\t])','', textofin,)\n",
    "  textofin = nlp(textofin)\n",
    "  lema = []\n",
    "  for token in textofin:\n",
    "    lema.append(token.lemma_)\n",
    "\n",
    "  textofin = lema\n",
    "  textofin = ' '.join(textofin)\n",
    "  return textofin\n",
    "  \n",
    "def clasification_to_num(text):\n",
    "    if text == 'exterior':\n",
    "        return 0\n",
    "    elif text == 'economia':\n",
    "        return 1\n",
    "    elif text == 'opinion' :\n",
    "        return 2\n",
    "    elif text == 'competencia':\n",
    "        return 3\n",
    "    elif text == 'apoyo':\n",
    "        return 4\n",
    "    elif text == 'seguridad':\n",
    "        return 5\n",
    "  \n",
    "\n",
    "\n",
    "df[\"clean\"] = df[\"Texto\"].apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/danielhtoledo/reps/Machine_learning_project/prueba.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/danielhtoledo/reps/Machine_learning_project/prueba.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvm\u001b[39;00m \u001b[39mimport\u001b[39;00m SVC\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/danielhtoledo/reps/Machine_learning_project/prueba.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m tfidf \u001b[39m=\u001b[39m TfidfVectorizer(ngram_range\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/danielhtoledo/reps/Machine_learning_project/prueba.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m X \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mclean\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/danielhtoledo/reps/Machine_learning_project/prueba.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mclassification_spanish\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/danielhtoledo/reps/Machine_learning_project/prueba.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/danielhtoledo/reps/Machine_learning_project/prueba.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     X, y, train_size\u001b[39m=\u001b[39m\u001b[39m0.85\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/danielhtoledo/reps/Machine_learning_project/prueba.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "X = df[\"clean\"]\n",
    "y = df[\"classification_spanish\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.85, random_state=42\n",
    ")\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "model = SVC(kernel=\"linear\", random_state=30, probability=True)\n",
    "model.fit(X_train_vec, y_train)\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "clasification = pd.DataFrame(report).transpose()\n",
    "\n",
    "\n",
    "def predict_text(text):\n",
    "    resultado = clean_text(text)\n",
    "    resultado = tfidf.transform([resultado])\n",
    "    prediccion = model.predict(resultado)\n",
    "    probabilida = model.predict_proba(resultado)\n",
    "    print(probabilida)\n",
    "    return probabilida\n",
    "\n",
    "\n",
    "def match_category(category):\n",
    "    match category:\n",
    "        case \"0\":\n",
    "            return \"apoyo\"\n",
    "        case \"1\":\n",
    "            return \"competencia\"\n",
    "        case \"2\":\n",
    "            return \"construccion\"\n",
    "        case \"3\":\n",
    "            return \"corrupcion\"\n",
    "        case \"4\":\n",
    "            return \"economia\"\n",
    "        case \"5\":\n",
    "            return \"exterior\"\n",
    "        case \"6\":\n",
    "            return \"historia\"\n",
    "        case \"7\":\n",
    "            return \"opinion\"\n",
    "        case \"8\": \n",
    "            return \"salud\"\n",
    "        case \"9\":\n",
    "            return \"seguridad\"\n",
    "        case _:\n",
    "            return category\n",
    "def match_category2(category):\n",
    "    match category:\n",
    "        case 0:\n",
    "            return \"apoyo\"\n",
    "        case 1:\n",
    "            return \"competencia\"\n",
    "        case 2:\n",
    "            return \"construccion\"\n",
    "        case 3:\n",
    "            return \"corrupcion\"\n",
    "        case 4:\n",
    "            return \"economia\"\n",
    "        case 5:\n",
    "            return \"exterior\"\n",
    "        case 6:\n",
    "            return \"historia\"\n",
    "        case 7:\n",
    "            return \"opinion\"\n",
    "        case 8: \n",
    "            return \"salud\"\n",
    "        case 9:\n",
    "            return \"seguridad\"\n",
    "\n",
    "\n",
    "def predict(proba):\n",
    "    proba = list(proba[0])\n",
    "    print(proba)\n",
    "    maxx = max(proba)\n",
    "    index = proba.index(maxx)\n",
    "    return f\"La probabilidad es {maxx} y lo categoriza como {match_category2(index)}\"\n",
    "\n",
    "\n",
    "def clasification_rep():\n",
    "    clasification[\"Unnamed: 0\"] = clasification[\"Unnamed: 0\"].astype(str)\n",
    "\n",
    "    clasification[\"Unnamed: 0\"] = clasification[\"Unnamed: 0\"].apply(match_category)\n",
    "    a = clasification.rename(columns={\"Unnamed: 0\": \"Clasificación\", \"precision\" : \"Precision\"})\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "first = predict_text(\"Adultos mayores\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(predict(first))\n",
    "\n",
    "print(clasification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.04802358e-07 4.65235489e-07 9.99451418e-01 9.89789909e-06\n",
      "  3.25592431e-04 2.14661747e-05 1.98501383e-05 1.30873649e-05\n",
      "  6.89197121e-05 1.18848489e-05 7.70129315e-05]]\n",
      "[4.048023582290229e-07, 4.6523548908093876e-07, 0.9994514184619914, 9.897899088706479e-06, 0.0003255924306322247, 2.1466174706003473e-05, 1.985013834271561e-05, 1.3087364908048738e-05, 6.891971211436844e-05, 1.1884848906935497e-05, 7.701293146257646e-05]\n",
      "La probabilidad es 0.9994514184619914 y lo categoriza como 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first = predict_text(\"Vamos, como lo hacemos todos lunes, a informar quién es quién en los precios, también el avance en las obras, el avance en la construcción del aeropuerto de Santa Lucía, el avance en la construcción de la refinería de Dos Bocas.\")\n",
    "\n",
    "\n",
    "\n",
    "print(predict(first))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
